{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Author : Harrytsz\n",
    "* Github : https://github.com/harrytsz/Deep_Learning_Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get MNIST Dataset from : https://yann.lecun.exdb/mnist/     \n",
    "* Training set images: train-images-idx3-ubyte.gz (9.9 MB, 60,000)    \n",
    "* Training set labels: train-labels-idx1-ubyte.gz (29 KB, 60,000)    \n",
    "* Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 10,000)     \n",
    "* Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 10,000)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train (bool, optional): If True, creates dataset from ``training.pt``,otherwise from ``test.pt``\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/',train=True,transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/',train=False,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataLoader:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,    \n",
    "       batch_sampler=None, num_workers=0, collate_fn=<function default_collate>, \n",
    "       pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters:**\n",
    "\n",
    "* dataset (Dataset) – dataset from which to load the data.\n",
    "   \n",
    "* batch_size (int, optional) – how many samples per batch to load (default: 1).\n",
    "     \n",
    "* shuffle (bool, optional) – set to True to have the data reshuffled at every epoch (default: False).\n",
    "     \n",
    "* sampler (Sampler, optional) – defines the strategy to draw samples from the dataset. If specified, shuffle must be False.\n",
    "* batch_sampler (Sampler, optional) – like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
    "* num_workers (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)\n",
    "* collate_fn (callable, optional) – merges a list of samples to form a mini-batch.\n",
    "* pin_memory (bool, optional) – If True, the data loader will copy tensors into CUDA pinned memory before returning them.\n",
    "* drop_last (bool, optional) – set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)\n",
    "* timeout (numeric, optional) – if positive, the timeout value for collecting a batch from workers. Should always be non-negative. (default: 0)\n",
    "* worker_init_fn (callable, optional) – If not None, this will be called on each worker subprocess with the worker id (an int in [0, num_workers - 1]) as input, after seeding and before data loading. (default: None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loader:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) tensor([4, 2, 4, 8, 1, 0, 5, 0, 6, 3, 7, 6, 6, 4, 2, 4, 7, 0, 8, 3, 2, 2, 5, 3,\n",
      "        5, 4, 3, 0, 3, 3, 5, 4, 7, 9, 1, 5, 1, 5, 1, 3, 7, 4, 6, 9, 7, 2, 2, 6,\n",
      "        2, 4, 0, 6, 6, 3, 1, 7, 9, 7, 4, 6, 4, 4, 7, 4, 9, 8, 4, 5, 9, 4, 9, 6,\n",
      "        6, 6, 0, 2, 0, 3, 1, 1, 4, 2, 0, 7, 2, 1, 0, 1, 9, 1, 3, 4, 0, 7, 9, 2,\n",
      "        3, 9, 5, 6])\n",
      "#----------------------------------------------------------------#\n",
      "torch.Size([100, 1, 28, 28]) tensor([2, 4, 3, 4, 2, 6, 6, 6, 0, 1, 1, 1, 7, 7, 0, 8, 5, 3, 0, 6, 1, 6, 2, 9,\n",
      "        3, 5, 7, 1, 3, 6, 5, 7, 5, 1, 2, 3, 2, 3, 6, 1, 4, 5, 0, 2, 0, 1, 8, 5,\n",
      "        4, 9, 6, 0, 1, 7, 4, 7, 9, 4, 3, 9, 1, 5, 4, 5, 8, 7, 2, 7, 6, 5, 3, 2,\n",
      "        6, 1, 9, 6, 7, 9, 2, 5, 9, 7, 0, 1, 9, 5, 8, 7, 2, 0, 1, 9, 3, 9, 6, 0,\n",
      "        3, 6, 7, 7])\n",
      "#----------------------------------------------------------------#\n",
      "torch.Size([100, 1, 28, 28]) tensor([0, 5, 4, 8, 8, 3, 1, 1, 8, 3, 6, 7, 6, 3, 4, 9, 2, 2, 5, 9, 9, 3, 3, 8,\n",
      "        5, 8, 8, 7, 7, 3, 1, 9, 6, 3, 8, 3, 0, 4, 1, 5, 1, 6, 8, 7, 1, 3, 5, 5,\n",
      "        5, 8, 7, 7, 2, 5, 4, 1, 5, 1, 1, 7, 3, 2, 0, 4, 5, 1, 9, 1, 9, 7, 5, 4,\n",
      "        7, 3, 6, 3, 2, 1, 1, 3, 9, 0, 9, 0, 4, 5, 7, 9, 1, 1, 6, 0, 7, 8, 5, 3,\n",
      "        8, 8, 3, 7])\n",
      "#----------------------------------------------------------------#\n",
      "torch.Size([100, 1, 28, 28]) tensor([0, 8, 8, 7, 9, 8, 4, 3, 0, 3, 8, 3, 3, 0, 2, 6, 9, 3, 1, 0, 6, 9, 1, 4,\n",
      "        4, 5, 5, 9, 9, 3, 2, 7, 8, 5, 1, 5, 7, 4, 6, 4, 7, 1, 8, 5, 4, 7, 1, 7,\n",
      "        9, 7, 0, 2, 0, 7, 5, 3, 3, 8, 6, 9, 6, 7, 4, 0, 3, 5, 7, 8, 2, 2, 8, 5,\n",
      "        2, 4, 2, 8, 3, 4, 1, 1, 1, 5, 3, 0, 8, 7, 0, 6, 7, 7, 1, 7, 5, 5, 5, 2,\n",
      "        2, 6, 8, 8])\n",
      "#----------------------------------------------------------------#\n",
      "torch.Size([100, 1, 28, 28]) tensor([6, 6, 4, 8, 2, 7, 9, 2, 2, 9, 2, 9, 5, 3, 4, 5, 0, 3, 7, 2, 9, 3, 5, 5,\n",
      "        2, 1, 8, 6, 8, 9, 7, 8, 7, 8, 3, 8, 8, 0, 2, 1, 1, 1, 0, 5, 9, 5, 1, 9,\n",
      "        7, 6, 1, 6, 7, 6, 2, 0, 7, 2, 9, 9, 4, 6, 6, 4, 1, 3, 3, 5, 9, 9, 4, 9,\n",
      "        7, 1, 3, 2, 8, 2, 1, 6, 7, 6, 7, 6, 3, 1, 0, 2, 4, 8, 0, 1, 0, 1, 7, 6,\n",
      "        1, 7, 6, 9])\n",
      "#----------------------------------------------------------------#\n",
      "torch.Size([100, 1, 28, 28]) tensor([7, 0, 4, 5, 5, 0, 1, 1, 1, 5, 9, 8, 9, 8, 0, 7, 9, 3, 8, 0, 7, 0, 5, 6,\n",
      "        1, 4, 9, 7, 4, 0, 9, 4, 8, 0, 9, 3, 7, 7, 0, 7, 9, 7, 5, 2, 9, 1, 7, 0,\n",
      "        6, 2, 9, 1, 4, 9, 8, 3, 5, 6, 2, 2, 1, 5, 0, 2, 2, 5, 1, 6, 6, 0, 8, 1,\n",
      "        8, 5, 1, 2, 7, 3, 6, 8, 9, 1, 7, 1, 4, 2, 4, 5, 4, 9, 6, 8, 2, 7, 0, 3,\n",
      "        1, 3, 3, 3])\n",
      "#----------------------------------------------------------------#\n",
      "Train_Loader Type:  <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#----------------------------#\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    if (i % 100 == 0):\n",
    "        print(images.size(), labels)\n",
    "        print(\"#----------------------------------------------------------------#\")\n",
    "print(\"Train_Loader Type: \", type(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
    "\n",
    "* This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "* It is useful when training a classification problem with C classes.\n",
    "* The input is expected to contain scores for each class.\n",
    "* This criterion expects a class index (0 to C-1) as the target for each value of a 1D tensor of size minibatch\n",
    "\n",
    "**公式：**   \n",
    "$$loss(x, class) = - log(\\frac{exp(x[class])}{\\sum_{j}{exp(x[j])}}) = -x[class] + log(\\sum_{j}{exp(x[j])})$$\n",
    "* x[class] x[\\text {class}]x[class]:给实际类的打分\n",
    "* x 的形状：(N, C)where C = number of classes\n",
    "* class 的形状：(N) where each value is 0 ≤ targets[i]≤C−10≤targets[i]≤C−1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Training the Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/600], Loss: 2.2912\n",
      "Epoch [1/5], Step [101/600], Loss: 2.1792\n",
      "Epoch [1/5], Step [201/600], Loss: 2.0884\n",
      "Epoch [1/5], Step [301/600], Loss: 1.9997\n",
      "Epoch [1/5], Step [401/600], Loss: 1.9270\n",
      "Epoch [1/5], Step [501/600], Loss: 1.7632\n",
      "Epoch [2/5], Step [1/600], Loss: 1.7664\n",
      "Epoch [2/5], Step [101/600], Loss: 1.7568\n",
      "Epoch [2/5], Step [201/600], Loss: 1.6411\n",
      "Epoch [2/5], Step [301/600], Loss: 1.6384\n",
      "Epoch [2/5], Step [401/600], Loss: 1.5296\n",
      "Epoch [2/5], Step [501/600], Loss: 1.5978\n",
      "Epoch [3/5], Step [1/600], Loss: 1.4466\n",
      "Epoch [3/5], Step [101/600], Loss: 1.4550\n",
      "Epoch [3/5], Step [201/600], Loss: 1.4523\n",
      "Epoch [3/5], Step [301/600], Loss: 1.5044\n",
      "Epoch [3/5], Step [401/600], Loss: 1.3375\n",
      "Epoch [3/5], Step [501/600], Loss: 1.2279\n",
      "Epoch [4/5], Step [1/600], Loss: 1.1642\n",
      "Epoch [4/5], Step [101/600], Loss: 1.2314\n",
      "Epoch [4/5], Step [201/600], Loss: 1.2756\n",
      "Epoch [4/5], Step [301/600], Loss: 1.0063\n",
      "Epoch [4/5], Step [401/600], Loss: 1.2180\n",
      "Epoch [4/5], Step [501/600], Loss: 1.0275\n",
      "Epoch [5/5], Step [1/600], Loss: 1.0891\n",
      "Epoch [5/5], Step [101/600], Loss: 1.0737\n",
      "Epoch [5/5], Step [201/600], Loss: 1.0846\n",
      "Epoch [5/5], Step [301/600], Loss: 1.0987\n",
      "Epoch [5/5], Step [401/600], Loss: 0.9743\n",
      "Epoch [5/5], Step [501/600], Loss: 1.0623\n"
     ]
    }
   ],
   "source": [
    "# Define Logistic Regression Model\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dims, output_dims, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "LR_Model = LR(input_size, num_classes)\n",
    "\n",
    "# Define the loss function of Logistic Regression\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = torch.optim.SGD(LR_Model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 将图像序列转换至大小为 (batch_size, input_size), 应为 (100, 784)\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        \n",
    "        # Forward \n",
    "        y_pred = LR_Model(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i % 100 == 0):\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 82 %.\n"
     ]
    }
   ],
   "source": [
    "# 在测试阶段，为了运行内存效率，就不需要计算梯度了\n",
    "# pytorch 默认每一次前向传播都会计算梯度\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = LR_Model(images)\n",
    "        # torch.max 的输出： out(tuple, optional) -- > the result tuple of two output tensor (max, max_indices)\n",
    "        max, predicted = torch.max(outputs.data, 1)\n",
    "        # print(max.data)\n",
    "        # print(predicted)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum()\n",
    "    print('Accuracy of the model on the 10000 test images: {} %.'.format(100*correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(LR_Model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
